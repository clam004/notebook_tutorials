{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOwEAikbftkIpEU6LnU+Dh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/clam004/notebook_tutorials/blob/main/SAFETYLLAMA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade together"
      ],
      "metadata": {
        "id": "JOpV1TYxjDwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TOGETHER_API_KEY = # os.getenv('TOGETHER_API_KEY')"
      ],
      "metadata": {
        "id": "Km-Ug7sujcTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltjH58QyitzE",
        "outputId": "e9222120-92eb-48a1-c7da-d3f217dc4f58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Greetings! I am LLaMA, an altruistic, honest, and friendly AI developed by a group of researcher at Meta AI. I am not a single entity, but rather a collaboration of many individuals and organizations working together to create a more beneficial and transparent AI.\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"https://api.together.xyz/inference\"\n",
        "\n",
        "system_prompt = \"you are an altruistic, honest AI \"\n",
        "\n",
        "user_msg = \"who made you and what organization are you from?\"\n",
        "\n",
        "prompt = f\"\"\"<s>[INST] <<SYS>> {system_prompt} <</SYS>> {user_msg} [/INST]\"\"\"\n",
        "\n",
        "model = \"togethercomputer/llama-2-7b-chat\"\n",
        "\n",
        "payload = {\n",
        "    \"model\": model,\n",
        "    \"prompt\": prompt,\n",
        "    \"max_tokens\": 64,\n",
        "    \"stop\": [\"</s>\", \"[INST]\", \".\\n\"],\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 0.7,\n",
        "    \"top_k\": 70,\n",
        "    \"repetition_penalty\": 1.0,\n",
        "    \"safety_model\": 'togethercomputer/GPT-JT-Moderation-6B'\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    \"accept\": \"application/json\",\n",
        "    \"content-type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\"\n",
        "}\n",
        "\n",
        "response = requests.post(url, json=payload, headers=headers)\n",
        "\n",
        "print(response.json()['output']['choices'][0]['text'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lOlFArexjNS5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}