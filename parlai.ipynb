{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parlai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:14 | building dictionary first...\n",
      "19:29:14 | Opt:\n",
      "19:29:14 |     adafactor_eps: '(1e-30, 0.001)'\n",
      "19:29:14 |     adam_eps: 1e-08\n",
      "19:29:14 |     add_p1_after_newln: False\n",
      "19:29:14 |     aggregate_micro: False\n",
      "19:29:14 |     allow_missing_init_opts: False\n",
      "19:29:14 |     attention: dot\n",
      "19:29:14 |     attention_length: 48\n",
      "19:29:14 |     attention_time: post\n",
      "19:29:14 |     batchsize: 1\n",
      "19:29:14 |     beam_block_full_context: True\n",
      "19:29:14 |     beam_block_list_filename: None\n",
      "19:29:14 |     beam_block_ngram: -1\n",
      "19:29:14 |     beam_context_block_ngram: -1\n",
      "19:29:14 |     beam_delay: 30\n",
      "19:29:14 |     beam_length_penalty: 0.65\n",
      "19:29:14 |     beam_min_length: 1\n",
      "19:29:14 |     beam_size: 1\n",
      "19:29:14 |     betas: '(0.9, 0.999)'\n",
      "19:29:14 |     bidirectional: False\n",
      "19:29:14 |     bpe_add_prefix_space: None\n",
      "19:29:14 |     bpe_debug: False\n",
      "19:29:14 |     bpe_dropout: None\n",
      "19:29:14 |     bpe_merge: None\n",
      "19:29:14 |     bpe_vocab: None\n",
      "19:29:14 |     compute_tokenized_bleu: False\n",
      "19:29:14 |     datapath: '/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/data'\n",
      "19:29:14 |     datatype: train\n",
      "19:29:14 |     decoder: same\n",
      "19:29:14 |     delimiter: '\\n'\n",
      "19:29:14 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "19:29:14 |     dict_endtoken: __end__\n",
      "19:29:14 |     dict_file: from_scratch_model/model.dict\n",
      "19:29:14 |     dict_include_test: False\n",
      "19:29:14 |     dict_include_valid: False\n",
      "19:29:14 |     dict_initpath: None\n",
      "19:29:14 |     dict_language: english\n",
      "19:29:14 |     dict_loaded: False\n",
      "19:29:14 |     dict_lower: False\n",
      "19:29:14 |     dict_max_ngram_size: -1\n",
      "19:29:14 |     dict_maxexs: -1\n",
      "19:29:14 |     dict_maxtokens: -1\n",
      "19:29:14 |     dict_minfreq: 0\n",
      "19:29:14 |     dict_nulltoken: __null__\n",
      "19:29:14 |     dict_starttoken: __start__\n",
      "19:29:14 |     dict_textfields: text,labels\n",
      "19:29:14 |     dict_tokenizer: re\n",
      "19:29:14 |     dict_unktoken: __unk__\n",
      "19:29:14 |     display_examples: False\n",
      "19:29:14 |     download_path: None\n",
      "19:29:14 |     dropout: 0.1\n",
      "19:29:14 |     dynamic_batching: None\n",
      "19:29:14 |     embedding_projection: random\n",
      "19:29:14 |     embedding_type: random\n",
      "19:29:14 |     embeddingsize: 128\n",
      "19:29:14 |     eval_batchsize: None\n",
      "19:29:14 |     eval_dynamic_batching: None\n",
      "19:29:14 |     evaltask: None\n",
      "19:29:14 |     final_extra_opt: \n",
      "19:29:14 |     force_fp16_tokens: False\n",
      "19:29:14 |     fp16: False\n",
      "19:29:14 |     fp16_impl: safe\n",
      "19:29:14 |     gpu: -1\n",
      "19:29:14 |     gradient_clip: 0.1\n",
      "19:29:14 |     hiddensize: 128\n",
      "19:29:14 |     hide_labels: False\n",
      "19:29:14 |     history_add_global_end_token: None\n",
      "19:29:14 |     history_reversed: False\n",
      "19:29:14 |     history_size: -1\n",
      "19:29:14 |     image_cropsize: 224\n",
      "19:29:14 |     image_mode: no_image_model\n",
      "19:29:14 |     image_size: 256\n",
      "19:29:14 |     inference: greedy\n",
      "19:29:14 |     init_model: None\n",
      "19:29:14 |     init_opt: None\n",
      "19:29:14 |     input_dropout: 0.0\n",
      "19:29:14 |     interactive_mode: False\n",
      "19:29:14 |     invsqrt_lr_decay_gamma: -1\n",
      "19:29:14 |     is_debug: False\n",
      "19:29:14 |     label_truncate: None\n",
      "19:29:14 |     learningrate: 1\n",
      "19:29:14 |     load_from_checkpoint: True\n",
      "19:29:14 |     log_every_n_secs: -1\n",
      "19:29:14 |     log_every_n_steps: 50\n",
      "19:29:14 |     loglevel: info\n",
      "19:29:14 |     lookuptable: all\n",
      "19:29:14 |     lr_scheduler: reduceonplateau\n",
      "19:29:14 |     lr_scheduler_decay: 0.5\n",
      "19:29:14 |     lr_scheduler_patience: 3\n",
      "19:29:14 |     max_train_steps: -1\n",
      "19:29:14 |     max_train_time: 120.0\n",
      "19:29:14 |     metrics: default\n",
      "19:29:14 |     model: seq2seq\n",
      "19:29:14 |     model_file: from_scratch_model/model\n",
      "19:29:14 |     momentum: 0\n",
      "19:29:14 |     multitask_weights: [1]\n",
      "19:29:14 |     mutators: None\n",
      "19:29:14 |     nesterov: True\n",
      "19:29:14 |     no_cuda: False\n",
      "19:29:14 |     num_epochs: -1\n",
      "19:29:14 |     num_workers: 0\n",
      "19:29:14 |     numlayers: 2\n",
      "19:29:14 |     numsoftmax: 1\n",
      "19:29:14 |     nus: (0.7,)\n",
      "19:29:14 |     optimizer: sgd\n",
      "19:29:14 |     override: \"{'model_file': 'from_scratch_model/model', 'task': 'empathetic_dialogues', 'max_train_time': 120.0, 'batchsize': 16, 'model': 'seq2seq', 'attention': 'dot', 'lookuptable': 'all', 'truncate': 64}\"\n",
      "19:29:14 |     parlai_home: '/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages'\n",
      "19:29:14 |     person_tokens: False\n",
      "19:29:14 |     rank_candidates: False\n",
      "19:29:14 |     remove_political_convos: False\n",
      "19:29:14 |     rnn_class: lstm\n",
      "19:29:14 |     save_after_valid: False\n",
      "19:29:14 |     save_every_n_secs: -1\n",
      "19:29:14 |     short_final_eval: False\n",
      "19:29:14 |     skip_generation: False\n",
      "19:29:14 |     special_tok_lst: None\n",
      "19:29:14 |     split_lines: False\n",
      "19:29:14 |     starttime: Mar23_19-29\n",
      "19:29:14 |     task: empathetic_dialogues\n",
      "19:29:14 |     temperature: 1.0\n",
      "19:29:14 |     tensorboard_log: False\n",
      "19:29:14 |     tensorboard_logdir: None\n",
      "19:29:14 |     text_truncate: None\n",
      "19:29:14 |     topk: 10\n",
      "19:29:14 |     topp: 0.9\n",
      "19:29:14 |     train_experiencer_only: False\n",
      "19:29:14 |     truncate: 64\n",
      "19:29:14 |     update_freq: 1\n",
      "19:29:14 |     use_reply: label\n",
      "19:29:14 |     validation_cutoff: 1.0\n",
      "19:29:14 |     validation_every_n_epochs: -1\n",
      "19:29:14 |     validation_every_n_secs: -1\n",
      "19:29:14 |     validation_every_n_steps: -1\n",
      "19:29:14 |     validation_max_exs: -1\n",
      "19:29:14 |     validation_metric: accuracy\n",
      "19:29:14 |     validation_metric_mode: None\n",
      "19:29:14 |     validation_patience: 10\n",
      "19:29:14 |     validation_share_agent: False\n",
      "19:29:14 |     verbose: False\n",
      "19:29:14 |     wandb_entity: None\n",
      "19:29:14 |     wandb_log: False\n",
      "19:29:14 |     wandb_name: None\n",
      "19:29:14 |     wandb_project: None\n",
      "19:29:14 |     warmup_rate: 0.0001\n",
      "19:29:14 |     warmup_updates: -1\n",
      "19:29:14 |     weight_decay: None\n",
      "19:29:14 | Current ParlAI commit: 914499a75197943485f1b26facb13e8a6080987f\n",
      "19:29:14 | Current internal commit: 914499a75197943485f1b26facb13e8a6080987f\n",
      "19:29:14 | Current fb commit: 914499a75197943485f1b26facb13e8a6080987f\n",
      "19:29:14 | creating task(s): empathetic_dialogues\n",
      "[EmpatheticDialoguesTeacher] Only use experiencer side? False, datatype: train:ordered:stream\n",
      "[building data: /media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/data/empatheticdialogues]\n",
      "19:29:14 | Downloading http://parl.ai/downloads/empatheticdialogues/empatheticdialogues.tar.gz to /media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/data/empatheticdialogues/empatheticdialogues.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading empatheticdialogues.tar.gz: 100%|████████████████████████████████████████████████| 28.0M/28.0M [00:02<00:00, 9.85MB/s]\n",
      "Building dictionary: 100%|██████████████████████████████████████████████████████████████████| 64.6k/64.6k [00:02<00:00, 28.8kex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:21 | Saving dictionary to from_scratch_model/model.dict\n",
      "19:29:21 | dictionary built with 22419 tokens in 0.0s\n",
      "19:29:21 | No model with opt yet at: from_scratch_model/model(.opt)\n",
      "19:29:21 | Using CUDA\n",
      "19:29:21 | loading dictionary from from_scratch_model/model.dict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:21 | num words = 22419\n",
      "19:29:21 | Total parameters: 3,453,203 (3,453,203 trainable)\n",
      "19:29:21 | Opt:\n",
      "19:29:21 |     adafactor_eps: '(1e-30, 0.001)'\n",
      "19:29:21 |     adam_eps: 1e-08\n",
      "19:29:21 |     add_p1_after_newln: False\n",
      "19:29:21 |     aggregate_micro: False\n",
      "19:29:21 |     allow_missing_init_opts: False\n",
      "19:29:21 |     attention: dot\n",
      "19:29:21 |     attention_length: 48\n",
      "19:29:21 |     attention_time: post\n",
      "19:29:21 |     batchsize: 16\n",
      "19:29:21 |     beam_block_full_context: True\n",
      "19:29:21 |     beam_block_list_filename: None\n",
      "19:29:21 |     beam_block_ngram: -1\n",
      "19:29:21 |     beam_context_block_ngram: -1\n",
      "19:29:21 |     beam_delay: 30\n",
      "19:29:21 |     beam_length_penalty: 0.65\n",
      "19:29:21 |     beam_min_length: 1\n",
      "19:29:21 |     beam_size: 1\n",
      "19:29:21 |     betas: '(0.9, 0.999)'\n",
      "19:29:21 |     bidirectional: False\n",
      "19:29:21 |     bpe_add_prefix_space: None\n",
      "19:29:21 |     bpe_debug: False\n",
      "19:29:21 |     bpe_dropout: None\n",
      "19:29:21 |     bpe_merge: None\n",
      "19:29:21 |     bpe_vocab: None\n",
      "19:29:21 |     compute_tokenized_bleu: False\n",
      "19:29:21 |     datapath: '/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/data'\n",
      "19:29:21 |     datatype: train\n",
      "19:29:21 |     decoder: same\n",
      "19:29:21 |     delimiter: '\\n'\n",
      "19:29:21 |     dict_class: parlai.core.dict:DictionaryAgent\n",
      "19:29:21 |     dict_endtoken: __end__\n",
      "19:29:21 |     dict_file: from_scratch_model/model.dict\n",
      "19:29:21 |     dict_include_test: False\n",
      "19:29:21 |     dict_include_valid: False\n",
      "19:29:21 |     dict_initpath: None\n",
      "19:29:21 |     dict_language: english\n",
      "19:29:21 |     dict_loaded: True\n",
      "19:29:21 |     dict_lower: False\n",
      "19:29:21 |     dict_max_ngram_size: -1\n",
      "19:29:21 |     dict_maxexs: -1\n",
      "19:29:21 |     dict_maxtokens: -1\n",
      "19:29:21 |     dict_minfreq: 0\n",
      "19:29:21 |     dict_nulltoken: __null__\n",
      "19:29:21 |     dict_starttoken: __start__\n",
      "19:29:21 |     dict_textfields: text,labels\n",
      "19:29:21 |     dict_tokenizer: re\n",
      "19:29:21 |     dict_unktoken: __unk__\n",
      "19:29:21 |     display_examples: False\n",
      "19:29:21 |     download_path: None\n",
      "19:29:21 |     dropout: 0.1\n",
      "19:29:21 |     dynamic_batching: None\n",
      "19:29:21 |     embedding_projection: random\n",
      "19:29:21 |     embedding_type: random\n",
      "19:29:21 |     embeddingsize: 128\n",
      "19:29:21 |     eval_batchsize: None\n",
      "19:29:21 |     eval_dynamic_batching: None\n",
      "19:29:21 |     evaltask: None\n",
      "19:29:21 |     final_extra_opt: \n",
      "19:29:21 |     force_fp16_tokens: False\n",
      "19:29:21 |     fp16: False\n",
      "19:29:21 |     fp16_impl: safe\n",
      "19:29:21 |     gpu: -1\n",
      "19:29:21 |     gradient_clip: 0.1\n",
      "19:29:21 |     hiddensize: 128\n",
      "19:29:21 |     hide_labels: False\n",
      "19:29:21 |     history_add_global_end_token: None\n",
      "19:29:21 |     history_reversed: False\n",
      "19:29:21 |     history_size: -1\n",
      "19:29:21 |     image_cropsize: 224\n",
      "19:29:21 |     image_mode: raw\n",
      "19:29:21 |     image_size: 256\n",
      "19:29:21 |     inference: greedy\n",
      "19:29:21 |     init_model: None\n",
      "19:29:21 |     init_opt: None\n",
      "19:29:21 |     input_dropout: 0.0\n",
      "19:29:21 |     interactive_mode: False\n",
      "19:29:21 |     invsqrt_lr_decay_gamma: -1\n",
      "19:29:21 |     is_debug: False\n",
      "19:29:21 |     label_truncate: None\n",
      "19:29:21 |     learningrate: 1\n",
      "19:29:21 |     load_from_checkpoint: True\n",
      "19:29:21 |     log_every_n_secs: -1\n",
      "19:29:21 |     log_every_n_steps: 50\n",
      "19:29:21 |     loglevel: info\n",
      "19:29:21 |     lookuptable: all\n",
      "19:29:21 |     lr_scheduler: reduceonplateau\n",
      "19:29:21 |     lr_scheduler_decay: 0.5\n",
      "19:29:21 |     lr_scheduler_patience: 3\n",
      "19:29:21 |     max_train_steps: -1\n",
      "19:29:21 |     max_train_time: 120.0\n",
      "19:29:21 |     metrics: default\n",
      "19:29:21 |     model: seq2seq\n",
      "19:29:21 |     model_file: from_scratch_model/model\n",
      "19:29:21 |     momentum: 0\n",
      "19:29:21 |     multitask_weights: [1]\n",
      "19:29:21 |     mutators: None\n",
      "19:29:21 |     nesterov: True\n",
      "19:29:21 |     no_cuda: False\n",
      "19:29:21 |     num_epochs: -1\n",
      "19:29:21 |     num_workers: 0\n",
      "19:29:21 |     numlayers: 2\n",
      "19:29:21 |     numsoftmax: 1\n",
      "19:29:21 |     nus: (0.7,)\n",
      "19:29:21 |     optimizer: sgd\n",
      "19:29:21 |     override: \"{'model_file': 'from_scratch_model/model', 'task': 'empathetic_dialogues', 'max_train_time': 120.0, 'batchsize': 16, 'model': 'seq2seq', 'attention': 'dot', 'lookuptable': 'all', 'truncate': 64}\"\n",
      "19:29:21 |     parlai_home: '/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages'\n",
      "19:29:21 |     person_tokens: False\n",
      "19:29:21 |     rank_candidates: False\n",
      "19:29:21 |     remove_political_convos: False\n",
      "19:29:21 |     rnn_class: lstm\n",
      "19:29:21 |     save_after_valid: False\n",
      "19:29:21 |     save_every_n_secs: -1\n",
      "19:29:21 |     short_final_eval: False\n",
      "19:29:21 |     skip_generation: False\n",
      "19:29:21 |     special_tok_lst: None\n",
      "19:29:21 |     split_lines: False\n",
      "19:29:21 |     starttime: Mar23_19-29\n",
      "19:29:21 |     task: empathetic_dialogues\n",
      "19:29:21 |     temperature: 1.0\n",
      "19:29:21 |     tensorboard_log: False\n",
      "19:29:21 |     tensorboard_logdir: None\n",
      "19:29:21 |     text_truncate: None\n",
      "19:29:21 |     topk: 10\n",
      "19:29:21 |     topp: 0.9\n",
      "19:29:21 |     train_experiencer_only: False\n",
      "19:29:21 |     truncate: 64\n",
      "19:29:21 |     update_freq: 1\n",
      "19:29:21 |     use_reply: label\n",
      "19:29:21 |     validation_cutoff: 1.0\n",
      "19:29:21 |     validation_every_n_epochs: -1\n",
      "19:29:21 |     validation_every_n_secs: -1\n",
      "19:29:21 |     validation_every_n_steps: -1\n",
      "19:29:21 |     validation_max_exs: -1\n",
      "19:29:21 |     validation_metric: accuracy\n",
      "19:29:21 |     validation_metric_mode: None\n",
      "19:29:21 |     validation_patience: 10\n",
      "19:29:21 |     validation_share_agent: False\n",
      "19:29:21 |     verbose: False\n",
      "19:29:21 |     wandb_entity: None\n",
      "19:29:21 |     wandb_log: False\n",
      "19:29:21 |     wandb_name: None\n",
      "19:29:21 |     wandb_project: None\n",
      "19:29:21 |     warmup_rate: 0.0001\n",
      "19:29:21 |     warmup_updates: -1\n",
      "19:29:21 |     weight_decay: None\n",
      "19:29:21 | Current ParlAI commit: 914499a75197943485f1b26facb13e8a6080987f\n",
      "19:29:21 | Current internal commit: 914499a75197943485f1b26facb13e8a6080987f\n",
      "19:29:22 | Current fb commit: 914499a75197943485f1b26facb13e8a6080987f\n",
      "19:29:22 | creating task(s): empathetic_dialogues\n",
      "[EmpatheticDialoguesTeacher] Only use experiencer side? False, datatype: train\n",
      "19:29:22 | training...\n",
      "19:29:26 | time:3s total_exs:800 total_steps:50 epochs:0.01\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen   ppl  \\\n",
      "   30.01     1 448.1  6827   .0950      2.002 243.8  800  .9673   .02122 16.58 9.284   1 264.4  4028   .0050      .0550 10762   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "       .06241         0                   50 712.4 10855 15.24\n",
      "\n",
      "19:29:29 | time:7s total_exs:1600 total_steps:100 epochs:0.02\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.69     1 463.6  6978   .1200      2.714 240.8  800  1.011   .02121  16.5 8.913   1 263.9  3972  .00125      .0125 7426   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .0886         0                  100 727.5 10950 15.06\n",
      "\n",
      "19:29:33 | time:10s total_exs:2400 total_steps:150 epochs:0.04\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.64     1 465.7  6927   .1013      2.531   238  800   1.04   .02123  16.9 8.638   1   269  4001   .0050      .0825 5642   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1044         0                  150 734.8 10928 14.88\n",
      "\n",
      "19:29:36 | time:14s total_exs:3200 total_steps:200 epochs:0.05\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.03     1   456  6845   .1087       2.53 240.1  800  1.082   .02118  16.1 8.527   1 256.9  3857   .0025     .04375 5048   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .1136         0                  200  713 10701 15.02\n",
      "\n",
      "19:29:39 | time:17s total_exs:4000 total_steps:250 epochs:0.06\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.36     1 454.1  6794   .0900      1.984 239.4  800  1.096   .02122 16.33   8.3   1 258.9  3874  .00625      .1500 4025   \n",
      "    token_acc  token_em  total_train_updates  tpb   tps   ups  \n",
      "        .1274         0                  250  713 10669 14.97\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:29:43 | time:20s total_exs:4800 total_steps:300 epochs:0.07\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.49     1 459.7  7029  .09625      2.757 244.6  800  1.116    .0212 16.43 8.271   1 262.9  4019  .00125     .00375 3911   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps  ups  \n",
      "        .1275         0                  300 722.6 11049 15.3\n",
      "\n",
      "19:29:46 | time:24s total_exs:5600 total_steps:350 epochs:0.09\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.36     1 456.8  7141  .09125      1.806 250.1  800   1.12   .01814 15.61  8.09   1 249.8  3904       0          0 3262   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1406         0                  350 706.6 11045 15.64\n",
      "\n",
      "19:29:49 | time:27s total_exs:6400 total_steps:400 epochs:0.10\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.08     1 461.6  6904   .0950      2.224 239.3  800  1.133   .02121 16.39 7.993   1 261.8  3915  .00375      .0250 2959   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1461         0                  400 723.4 10820 14.96\n",
      "\n",
      "19:29:52 | time:30s total_exs:7200 total_steps:450 epochs:0.11\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.58     1 465.8  7019   .1037      2.471 241.1  800  1.154   .02124 16.34 7.826   1 260.7  3929   .0050      .0500 2506   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1577         0                  450 726.5 10948 15.08\n",
      "\n",
      "19:29:55 | time:33s total_exs:8000 total_steps:500 epochs:0.12\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.36     1 455.2  7709   .0925      1.907 270.9  800  1.169   .02122 16.02 7.797   1 254.9  4317  .00625      .0825 2433   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1556         0                  500 710.2 12027 16.94\n",
      "\n",
      "19:29:58 | time:36s total_exs:8800 total_steps:550 epochs:0.14\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   29.74     1 449.6  7978   .0875      1.637 283.9  800  1.185   .01926 16.35 7.676   1 261.6  4642       0          0 2156   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1621         0                  550 711.2 12620 17.75\n",
      "\n",
      "19:30:01 | time:39s total_exs:9600 total_steps:600 epochs:0.15\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.96     1 466.8  7724   .1125      2.789 264.7  800  1.177   .02122 16.39 7.599   1 261.9  4333   .0025     .02625 1996   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1630         0                  600 728.7 12057 16.55\n",
      "\n",
      "19:30:04 | time:42s total_exs:10400 total_steps:650 epochs:0.16\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.83     1   468  7480   .1025      2.576 255.7  800  1.193   .02121 16.26 7.533   1 260.1  4157  .00125      .0050 1869   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1658         0                  650 728.2 11637 15.99\n",
      "\n",
      "19:30:07 | time:45s total_exs:11200 total_steps:700 epochs:0.17\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.26     1 464.6  7924   .0900      2.225 272.9  800  1.223   .02121 16.39 7.548   1 262.2  4471  .00125     .00625 1898   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1572         0                  700 726.8 12396 17.06\n",
      "\n",
      "19:30:10 | time:48s total_exs:12000 total_steps:750 epochs:0.19\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.46     1 459.2  7642   .1013      1.764 266.3  800  1.226   .02119 15.51 7.423   1   248  4128   .0025      .0075 1674   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1680         0                  750 707.2 11769 16.65\n",
      "\n",
      "19:30:14 | time:52s total_exs:12800 total_steps:800 epochs:0.20\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.04     1 450.9  6584  .09875       1.86 233.6  800  1.221   .02125 16.13 7.351   1   257  3752  .00625      .0725 1557   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1732         0                  800 707.9 10336 14.61\n",
      "\n",
      "19:30:17 | time:55s total_exs:13600 total_steps:850 epochs:0.21\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "    31.1     1 460.9  6690   .1037      2.292 232.2  800  1.232   .02124 16.59 7.335   1 264.6  3840  .00375      .0500 1533   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1695         0                  850 725.5 10530 14.52\n",
      "\n",
      "19:30:21 | time:59s total_exs:14400 total_steps:900 epochs:0.22\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.67     1 457.3  6542   .0975       2.09 228.9  800  1.234   .02125  16.9 7.293   1 269.4  3854   .0050     .05875 1470   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1730         0                  900 726.7 10397 14.31\n",
      "\n",
      "19:30:24 | time:62s total_exs:15200 total_steps:950 epochs:0.24\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.56     1 452.3  6606  .09625      2.295 233.7  800  1.247   .02125 16.25 7.301   1   259  3783  .00625      .0575 1481   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1708         0                  950 711.3 10390 14.61\n",
      "\n",
      "19:30:28 | time:66s total_exs:16000 total_steps:1000 epochs:0.25\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.59     1 455.6  6684  .08125      2.112 234.7  800  1.274   .02125 16.17 7.197   1   258  3785   .0050     .04375 1335   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1726         0                 1000 713.6 10469 14.68\n",
      "\n",
      "19:30:31 | time:69s total_exs:16800 total_steps:1050 epochs:0.26\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   29.34     1 438.2  6475   .0750      1.955 236.4  800  1.289   .02122 16.02 7.156   1   256  3782  .00375     .02375 1282   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1765         0                 1050 694.2 10258 14.78\n",
      "\n",
      "19:30:34 | time:72s total_exs:17600 total_steps:1100 epochs:0.27\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   29.84     1 440.6  6627  .07875      2.304 240.7  800  1.289   .02124 16.93 7.142   1 268.7  4042   .0075      .1313 1263   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1748         0                 1100 709.3 10669 15.05\n",
      "\n",
      "19:30:38 | time:76s total_exs:18400 total_steps:1150 epochs:0.28\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.03     1   450  6743  .09125      1.904 239.7  800  1.276   .02125 16.47 7.092   1 262.8  3938   .0050     .04375 1203   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1780         0                 1150 712.9 10681 14.99\n",
      "\n",
      "19:30:41 | time:79s total_exs:19200 total_steps:1200 epochs:0.30\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   29.38     1 443.1  6800   .0825      1.686 245.5  800  1.288   .02126 16.53 7.068   1 263.8  4049   .0050      .0450 1173   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1786         0                 1200 706.9 10849 15.35\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19:30:44 | time:82s total_exs:20000 total_steps:1250 epochs:0.31\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   31.87     1 465.5  6965   .1037      2.775 239.4  800  1.312   .02127 16.66 7.061   1 265.7  3976  .00375     .04875 1166   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1738         0                 1250 731.2 10941 14.97\n",
      "\n",
      "19:30:48 | time:86s total_exs:20800 total_steps:1300 epochs:0.32\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.04     1 445.6  6310  .09375      2.195 226.6  800  1.282   .02127    17 6.932   1 271.8  3849   .0025      .0125 1024   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1894         0                 1300 717.4 10160 14.17\n",
      "\n",
      "19:30:51 | time:89s total_exs:21600 total_steps:1350 epochs:0.33\n",
      "    clen  clip  ctpb  ctps  ctrunc  ctrunclen  exps  exs  gnorm  gpu_mem  llen  loss  lr  ltpb  ltps  ltrunc  ltrunclen  ppl  \\\n",
      "   30.25     1 448.7  6778  .09875        2.2 241.7  800  1.315   .02125 16.44 6.949   1 262.6  3967  .00125      .0275 1042   \n",
      "    token_acc  token_em  total_train_updates   tpb   tps   ups  \n",
      "        .1853         0                 1350 711.4 10746 15.11\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmkdir -p from_scratch_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparlai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrain_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrainModel\n\u001b[0;32m----> 6\u001b[0m \u001b[43mTrainModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we MUST provide a filename\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfrom_scratch_model/model\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# train on empathetic dialogues\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mempathetic_dialogues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# limit training time to 2 minutes, and a batchsize of 16\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_train_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatchsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we specify the model type as seq2seq\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseq2seq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# some hyperparamter choices. We'll use attention. We could use pretrained\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# embeddings too, with embedding_type='fasttext', but they take a long\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# time to download.\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# tie the word embeddings of the encoder/decoder/softmax.\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlookuptable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# truncate text and labels at 64 tokens, for memory and time savings\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/core/script.py:127\u001b[0m, in \u001b[0;36mParlaiScript.main\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_args(args)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m kwargs:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_run_args(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/core/script.py:92\u001b[0m, in \u001b[0;36mParlaiScript._run_kwargs\u001b[0;34m(cls, kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39msetup_args()\n\u001b[1;32m     91\u001b[0m opt \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mparse_kwargs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_from_parser_and_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/core/script.py:108\u001b[0m, in \u001b[0;36mParlaiScript._run_from_parser_and_opt\u001b[0;34m(cls, opt, parser)\u001b[0m\n\u001b[1;32m    106\u001b[0m script \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m(opt)\n\u001b[1;32m    107\u001b[0m script\u001b[38;5;241m.\u001b[39mparser \u001b[38;5;241m=\u001b[39m parser\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscript\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/scripts/train_model.py:998\u001b[0m, in \u001b[0;36mTrainModel.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loop \u001b[38;5;241m=\u001b[39m TrainLoop(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt)\n\u001b[0;32m--> 998\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/scripts/train_model.py:950\u001b[0m, in \u001b[0;36mTrainLoop.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    945\u001b[0m \u001b[38;5;124;03mPerform a training run.\u001b[39;00m\n\u001b[1;32m    946\u001b[0m \n\u001b[1;32m    947\u001b[0m \u001b[38;5;124;03m:return: tuple of reports (validation_report, test_report)\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    949\u001b[0m opt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _train_log \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_steps():\n\u001b[1;32m    951\u001b[0m     \u001b[38;5;66;03m# we've already done what we need in these\u001b[39;00m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# perform final validation/testing\u001b[39;00m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/scripts/train_model.py:857\u001b[0m, in \u001b[0;36mTrainLoop.train_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# do one example / batch of examples\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 857\u001b[0m         \u001b[43mworld\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparley\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m StopTrainException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    859\u001b[0m         logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopping from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/core/worlds.py:873\u001b[0m, in \u001b[0;36mBatchWorld.parley\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    869\u001b[0m         w\u001b[38;5;241m.\u001b[39mparley_init()\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_agents):\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;66;03m# The agent acts.\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m     batch_act \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_act\u001b[49m\u001b[43m(\u001b[49m\u001b[43magent_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_observations\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts[agent_idx] \u001b[38;5;241m=\u001b[39m batch_act\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# We possibly execute this action in the world.\u001b[39;00m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/core/worlds.py:841\u001b[0m, in \u001b[0;36mBatchWorld.batch_act\u001b[0;34m(self, agent_idx, batch_observation)\u001b[0m\n\u001b[1;32m    839\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworld\u001b[38;5;241m.\u001b[39mget_agents()[agent_idx]\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_act\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 841\u001b[0m     batch_actions \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_act\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_observation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    842\u001b[0m     \u001b[38;5;66;03m# Store the actions locally in each world.\u001b[39;00m\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, w \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworlds):\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/core/torch_agent.py:2234\u001b[0m, in \u001b[0;36mTorchAgent.batch_act\u001b[0;34m(self, observations)\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_training:\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# register the start of updates for later counting when they occur\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_metrics\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mups\u001b[39m\u001b[38;5;124m'\u001b[39m, GlobalTimerMetric(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m-> 2234\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2236\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m   2237\u001b[0m         \u001b[38;5;66;03m# save memory and compute by disabling autograd.\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m         \u001b[38;5;66;03m# use `with torch.enable_grad()` to gain back gradients.\u001b[39;00m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/core/torch_generator_agent.py:735\u001b[0m, in \u001b[0;36mTorchGeneratorAgent.train_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    734\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(batch)\n\u001b[0;32m--> 735\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_params()\n\u001b[1;32m    737\u001b[0m     oom_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/parlai/core/torch_agent.py:2322\u001b[0m, in \u001b[0;36mTorchAgent.backward\u001b[0;34m(self, loss)\u001b[0m\n\u001b[1;32m   2320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mbackward(loss, update_main_grads\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2322\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/carson/New Volume/parlai/notebook_tutorials/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# we'll save it in the \"from_scratch_model\" directory\n",
    "!rm -rf from_scratch_model\n",
    "!mkdir -p from_scratch_model\n",
    "\n",
    "from parlai.scripts.train_model import TrainModel\n",
    "TrainModel.main(\n",
    "    # we MUST provide a filename\n",
    "    model_file='from_scratch_model/model',\n",
    "    # train on empathetic dialogues\n",
    "    task='empathetic_dialogues',\n",
    "    # limit training time to 2 minutes, and a batchsize of 16\n",
    "    max_train_time=2 * 60,\n",
    "    batchsize=16,\n",
    "    \n",
    "    # we specify the model type as seq2seq\n",
    "    model='seq2seq',\n",
    "    # some hyperparamter choices. We'll use attention. We could use pretrained\n",
    "    # embeddings too, with embedding_type='fasttext', but they take a long\n",
    "    # time to download.\n",
    "    attention='dot',\n",
    "    # tie the word embeddings of the encoder/decoder/softmax.\n",
    "    lookuptable='all',\n",
    "    # truncate text and labels at 64 tokens, for memory and time savings\n",
    "    truncate=64,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
